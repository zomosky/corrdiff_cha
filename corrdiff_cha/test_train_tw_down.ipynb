{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:07.578710Z",
     "start_time": "2024-11-13T09:59:04.574855Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, time, psutil, hydra, torch\n",
    "os.environ['OMP_NUM_THREADS'] = '20'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '20'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "from hydra.utils import to_absolute_path\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from modulus import Module\n",
    "from modulus.models.diffusion import UNet, EDMPrecondSR\n",
    "from modulus.distributed import DistributedManager\n",
    "from modulus.metrics.diffusion import RegressionLoss, ResLoss\n",
    "from modulus.launch.logging import PythonLogger, RankZeroLoggingWrapper\n",
    "from modulus.launch.utils import load_checkpoint, save_checkpoint\n",
    "from datasets.dataset import init_train_valid_datasets_from_config\n",
    "from helpers.train_helpers import (\n",
    "    set_patch_shape,\n",
    "    set_seed,\n",
    "    configure_cuda_for_consistent_precision,\n",
    "    compute_num_accumulation_rounds,\n",
    "    handle_and_clip_gradients,\n",
    "    is_time_for_periodic_task,\n",
    ")\n",
    "### downsample data size\n",
    "def datacrop(data,size):\n",
    "    start = data.shape[2]//2 - size//2\n",
    "    return data[:, :, start:start + size, start:start + size]\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0558a39a5c13478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:08.344230Z",
     "start_time": "2024-11-13T09:59:08.238993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============CorrDiff Downscale Conf============\n",
      "Conf list: ['dataset', 'model', 'training', 'validation']\n",
      "\n",
      "Conf Para --> dataset\n",
      "<<{'type': 'cwb', 'data_path': '/code/2023-01-24-cwb-4years.zarr', 'in_channels': [0, 1, 2, 3, 4, 9, 10, 11, 12, 17, 18, 19], 'out_channels': [0, 17, 18, 19], 'img_shape_x': 448, 'img_shape_y': 448, 'add_grid': True, 'ds_factor': 4, 'min_path': None, 'max_path': None, 'global_means_path': None, 'global_stds_path': None}>>\n",
      "\n",
      "Conf Para --> model\n",
      "<<{'name': 'diffusion', 'hr_mean_conditioning': False}>>\n",
      "\n",
      "Conf Para --> training\n",
      "<<{'hp': {'training_duration': 200000000, 'total_batch_size': 256, 'batch_size_per_gpu': 2, 'lr': 0.0002, 'grad_clip_threshold': None, 'lr_decay': 1, 'lr_rampup': 10000000}, 'perf': {'fp_optimizations': 'fp32', 'dataloader_workers': 4, 'songunet_checkpoint_level': 0}, 'io': {'regression_checkpoint_path': 'checkpoints/regression.mdlus', 'print_progress_freq': 1000, 'save_checkpoint_freq': 5000, 'validation_freq': 5000, 'validation_steps': 10}}>>\n",
      "\n",
      "Conf Para --> validation\n",
      "<<{'train': False, 'all_times': False}>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sprixin/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config_training_diffusion': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "\n",
    "## 解析配置文件\n",
    "with initialize(config_path='conf',version_base= '1.2'):\n",
    "    mainconf = compose(config_name = 'config_training_diffusion')\n",
    "    confkey = list(mainconf.keys())\n",
    "print('============CorrDiff Downscale Conf============')\n",
    "print(f\"Conf list: {confkey}\")\n",
    "for confn in confkey:\n",
    "    print(f\"\\nConf Para --> {confn}\")\n",
    "    print(f\"<<{mainconf[confn]}>>\")\n",
    "cfg = mainconf\n",
    "dataset_cfg = OmegaConf.to_container(cfg.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444a8a60930e7b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:09.870082Z",
     "start_time": "2024-11-13T09:59:09.833354Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:59:09 - main - INFO] \u001b[94mSaving the outputs in /home/sprixin/test/zhangmy/corrdiff\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "cfg.dataset.out_channels = [0, 1, 2, 3]\n",
    "cfg.training.hp.training_duration = 8000000\n",
    "cfg.training.perf.dataloader_workers = 10\n",
    "cfg.training.hp.lr_decay = 0.97\n",
    "cfg.training.hp.lr = 0.00015\n",
    "cfg.dataset.data_path='/home/sprixin/test/zhangmy/cwa_dataset/cwa_dataset.zarr'\n",
    "cfg.training.hp.batch_size_per_gpu=16\n",
    "cfg.training.io.regression_checkpoint_path='/home/sprixin/test/zhangmy/corrdiff/outputs/regression/checkpoints_regression/UNet.0.2000128.mdlus'\n",
    "###\n",
    "DistributedManager.initialize()\n",
    "dist = DistributedManager()\n",
    "\n",
    "# Initialize loggers\n",
    "if dist.rank == 0:\n",
    "    writer = SummaryWriter(log_dir=\"tensorboard\")\n",
    "logger = PythonLogger(\"main\")  # General python logger\n",
    "logger0 = RankZeroLoggingWrapper(logger, dist)  # Rank 0 logger\n",
    "\n",
    "# Resolve and parse configs\n",
    "OmegaConf.resolve(cfg)\n",
    "dataset_cfg = OmegaConf.to_container(cfg.dataset)  # TODO needs better handling\n",
    "if hasattr(cfg, \"validation_dataset\"):\n",
    "    validation_dataset_cfg = OmegaConf.to_container(cfg.validation_dataset)\n",
    "else:\n",
    "    validation_dataset_cfg = None\n",
    "fp_optimizations = cfg.training.perf.fp_optimizations\n",
    "fp16 = fp_optimizations == \"fp16\"\n",
    "enable_amp = fp_optimizations.startswith(\"amp\")\n",
    "amp_dtype = torch.float16 if (fp_optimizations == \"amp-fp16\") else torch.bfloat16\n",
    "logger.info(f\"Saving the outputs in {os.getcwd()}\")\n",
    "\n",
    "# Set seeds and configure CUDA and cuDNN settings to ensure consistent precision\n",
    "set_seed(dist.rank)\n",
    "configure_cuda_for_consistent_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc64af1d64edff6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:11.885020Z",
     "start_time": "2024-11-13T09:59:11.239566Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the dataset\n",
    "data_loader_kwargs = {\n",
    "    \"pin_memory\": True,\n",
    "    \"num_workers\": cfg.training.perf.dataloader_workers,\n",
    "    \"prefetch_factor\": 2,\n",
    "}\n",
    "(\n",
    "    dataset,\n",
    "    dataset_iterator,\n",
    "    validation_dataset,\n",
    "    validation_dataset_iterator,\n",
    ") = init_train_valid_datasets_from_config(\n",
    "    dataset_cfg,\n",
    "    data_loader_kwargs,\n",
    "    batch_size=cfg.training.hp.batch_size_per_gpu,\n",
    "    seed=0,\n",
    "    validation_dataset_cfg=validation_dataset_cfg,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc5b1ed227ca0b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:12.586987Z",
     "start_time": "2024-11-13T09:59:12.580475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parse image configuration & update model args\n",
    "dataset_channels = len(dataset.input_channels())\n",
    "img_in_channels = dataset_channels\n",
    "img_shape = dataset.image_shape()\n",
    "img_out_channels = len(dataset.output_channels())\n",
    "# if cfg.model.hr_mean_conditioning:\n",
    "#     img_in_channels += img_out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb68bd8314bc471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:13.452938Z",
     "start_time": "2024-11-13T09:59:13.445951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:59:13 - main - INFO] \u001b[94mPatch-based training disabled\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Parse the patch shape\n",
    "if cfg.model.name == \"patched_diffusion\":\n",
    "    patch_shape_x = cfg.training.hp.patch_shape_x\n",
    "    patch_shape_y = cfg.training.hp.patch_shape_y\n",
    "else:\n",
    "    patch_shape_x = None\n",
    "    patch_shape_y = None\n",
    "patch_shape = (patch_shape_y, patch_shape_x)\n",
    "img_shape, patch_shape = set_patch_shape(img_shape, patch_shape)\n",
    "if patch_shape != img_shape:\n",
    "    logger0.info(\"Patch-based training enabled\")\n",
    "else:\n",
    "    logger0.info(\"Patch-based training disabled\")\n",
    "# interpolate global channel if patch-based model is used\n",
    "if img_shape[1] != patch_shape[1]:\n",
    "    img_in_channels += dataset_channels\n",
    "\n",
    "if cfg.model.name not in (\"regression\", \"diffusion\", \"patched_diffusion\"):\n",
    "    raise ValueError(\"Invalid model\")\n",
    "model_args = {  # default parameters for all networks\n",
    "    \"img_out_channels\": img_out_channels,\n",
    "    # \"img_resolution\": list(img_shape),\n",
    "    \"img_resolution\": img_shape[0],\n",
    "    \"use_fp16\": fp16,\n",
    "}\n",
    "standard_model_cfgs = {  # default parameters for different network types\n",
    "    \"regression\": {\n",
    "        \"img_channels\": 4,\n",
    "        \"N_grid_channels\": 4,\n",
    "        \"embedding_type\": \"zero\",\n",
    "    },\n",
    "    \"diffusion\": {\n",
    "        \"img_channels\": img_out_channels,\n",
    "        \"gridtype\": \"sinusoidal\",\n",
    "        \"N_grid_channels\": 4,\n",
    "    },\n",
    "    \"patched_diffusion\": {\n",
    "        \"img_channels\": img_out_channels,\n",
    "        \"gridtype\": \"learnable\",\n",
    "        \"N_grid_channels\": 100,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df63df92e8182c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:14.483228Z",
     "start_time": "2024-11-13T09:59:14.479103Z"
    }
   },
   "outputs": [],
   "source": [
    "model_args.update(standard_model_cfgs[cfg.model.name])\n",
    "if hasattr(cfg.model, \"model_args\"):  # override defaults from config file\n",
    "    model_args.update(OmegaConf.to_container(cfg.model.model_args))\n",
    "model_args_para = model_args.copy()\n",
    "N_grid_channels = model_args_para.pop('N_grid_channels')\n",
    "if cfg.model.name == \"regression\":\n",
    "    embedding_type = model_args_para.pop('embedding_type')\n",
    "else:\n",
    "    gridtype = model_args_para.pop('gridtype')\n",
    "###\n",
    "cropsize = 64\n",
    "model_args_para['img_resolution'] = cropsize\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c8a39ec753c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:26.066717Z",
     "start_time": "2024-11-13T09:59:15.806526Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:59:26 - main - INFO] \u001b[92mLoaded the pre-trained regression model\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if cfg.model.name == \"regression\":\n",
    "    model = UNet(\n",
    "        img_in_channels=img_in_channels,# + model_args[\"N_grid_channels\"],\n",
    "        **model_args_para,\n",
    "    )\n",
    "else:  # diffusion or patched diffusion\n",
    "    model = EDMPrecondSR(\n",
    "        img_in_channels=img_in_channels,# + model_args[\"N_grid_channels\"],\n",
    "        **model_args_para,\n",
    "    )\n",
    "model.train().requires_grad_(True).to(dist.device)\n",
    "\n",
    "# Enable distributed data parallel if applicable\n",
    "if dist.world_size > 1:\n",
    "    model = DistributedDataParallel(\n",
    "        model,\n",
    "        device_ids=[dist.local_rank],\n",
    "        broadcast_buffers=True,\n",
    "        output_device=dist.device,\n",
    "        find_unused_parameters=dist.find_unused_parameters,\n",
    "    )\n",
    "\n",
    "# Load the regression checkpoint if applicable\n",
    "if hasattr(cfg.training.io, \"regression_checkpoint_path\"):\n",
    "    regression_checkpoint_path = to_absolute_path(\n",
    "        cfg.training.io.regression_checkpoint_path\n",
    "    )\n",
    "    if not os.path.exists(regression_checkpoint_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Expected a this regression checkpoint but not found: {regression_checkpoint_path}\"\n",
    "        )\n",
    "    regression_net = Module.from_checkpoint(regression_checkpoint_path)\n",
    "    regression_net.eval().requires_grad_(False).to(dist.device)\n",
    "    logger0.success(\"Loaded the pre-trained regression model\")\n",
    "\n",
    "\n",
    "###\n",
    "patch_shape = (cropsize, cropsize)\n",
    "img_shape = (cropsize, cropsize)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1475d89d3953165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:28.555678Z",
     "start_time": "2024-11-13T09:59:27.886975Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:59:28 - main - INFO] \u001b[94mUsing 16 gradient accumulation rounds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the loss function\n",
    "patch_num = getattr(cfg.training.hp, \"patch_num\", 1)\n",
    "if cfg.model.name in (\"diffusion\", \"patched_diffusion\"):\n",
    "    loss_fn = ResLoss(\n",
    "        regression_net=regression_net,\n",
    "        img_shape_x=img_shape[1],\n",
    "        img_shape_y=img_shape[0],\n",
    "        patch_shape_x=patch_shape[1],\n",
    "        patch_shape_y=patch_shape[0],\n",
    "        patch_num=patch_num,\n",
    "        #hr_mean_conditioning=cfg.model.hr_mean_conditioning,\n",
    "    )\n",
    "elif cfg.model.name == \"regression\":\n",
    "    loss_fn = RegressionLoss()\n",
    "\n",
    "# Instantiate the optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(), lr=cfg.training.hp.lr, betas=[0.9, 0.999], eps=1e-8\n",
    ")\n",
    "\n",
    "# Record the current time to measure the duration of subsequent operations.\n",
    "start_time = time.time()\n",
    "\n",
    "# Compute the number of required gradient accumulation rounds\n",
    "# It is automatically used if batch_size_per_gpu * dist.world_size < total_batch_size\n",
    "batch_gpu_total, num_accumulation_rounds = compute_num_accumulation_rounds(\n",
    "    cfg.training.hp.total_batch_size,\n",
    "    cfg.training.hp.batch_size_per_gpu,\n",
    "    dist.world_size,\n",
    ")\n",
    "batch_size_per_gpu = cfg.training.hp.batch_size_per_gpu\n",
    "logger0.info(f\"Using {num_accumulation_rounds} gradient accumulation rounds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ad7fde437334a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:30.619240Z",
     "start_time": "2024-11-13T09:59:30.615927Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:59:30 - checkpoint - WARNING] \u001b[93mProvided checkpoint directory checkpoints_diffusion does not exist, skipping load\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Resume training from previous checkpoints if exists\n",
    "if dist.world_size > 1:\n",
    "    torch.distributed.barrier()\n",
    "try:\n",
    "    cur_nimg = load_checkpoint(\n",
    "        path=f\"checkpoints_{cfg.model.name}\",\n",
    "        models=model,\n",
    "        optimizer=optimizer,\n",
    "        device=dist.device,\n",
    "    )\n",
    "except:\n",
    "    cur_nimg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876c4ec5dd24c42c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:32.522862Z",
     "start_time": "2024-11-13T09:59:32.520106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:59:32 - main - INFO] \u001b[94mTraining for 8000000 images...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger0.info(f\"Training for {cfg.training.hp.training_duration} images...\")\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bf810789d0cb939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:59:46.973313Z",
     "start_time": "2024-11-13T09:59:34.201109Z"
    }
   },
   "outputs": [],
   "source": [
    "tick_start_nimg = cur_nimg\n",
    "tick_start_time = time.time()\n",
    "# Compute & accumulate gradients\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "loss_accum = 0\n",
    "for _ in range(num_accumulation_rounds):\n",
    "    img_clean, img_lr, labels = next(dataset_iterator)\n",
    "    ###\n",
    "    img_clean = datacrop(img_clean, size = cropsize)\n",
    "    img_lr = datacrop(img_lr, size = cropsize)\n",
    "    ###\n",
    "    img_clean = img_clean.to(dist.device).to(torch.float32).contiguous()\n",
    "    img_lr = img_lr.to(dist.device).to(torch.float32).contiguous()\n",
    "    labels = labels.to(dist.device).contiguous()\n",
    "    with torch.autocast(\"cuda\", dtype=torch.float32, enabled=enable_amp):\n",
    "        loss = loss_fn(\n",
    "            net=model,\n",
    "            img_clean=img_clean,\n",
    "            img_lr=img_lr,\n",
    "            labels=labels,\n",
    "            augment_pipe=None,\n",
    "        )\n",
    "    loss = loss.sum() / batch_size_per_gpu\n",
    "    loss_accum += loss / num_accumulation_rounds\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc31944e5be927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
